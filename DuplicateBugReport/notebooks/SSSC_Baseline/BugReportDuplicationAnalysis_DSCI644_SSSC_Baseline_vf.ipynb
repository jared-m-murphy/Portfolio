{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "c99EvWo1s9-x",
    "outputId": "fef3ad50-d0e1-4b1d-9782-a05d1e9d2047"
   },
   "outputs": [],
   "source": [
    "# Loading all required libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from util import make_w2v_embeddings\n",
    "from util import split_and_zero_padding\n",
    "from util import ManDist\n",
    "from time import time\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Embedding, LSTM, GRU, Conv1D, Conv2D, GlobalMaxPool1D, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# This will prompt for authorization.\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EEudw61-ld6r"
   },
   "outputs": [],
   "source": [
    "#Tokeniztion and stop word removal function\n",
    "def tokenization(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "preprocessed = lambda x: transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "H4SJ-tGNkOeY"
   },
   "outputs": [],
   "source": [
    "# Loading all required files, Note: Only Eclipse in this baseline scenario\n",
    "\n",
    "Eclipse_dups = pd.read_csv(\"EP_dup.csv\",sep=\";\", engine='python')\n",
    "Eclipse_nondups = pd.read_csv(\"EP_nondup.csv\",sep=\";\", engine='python')\n",
    "Eclipse_combined = pd.concat([Eclipse_dups, Eclipse_nondups], ignore_index=True, sort=False)\n",
    "\n",
    "# Mozilla_dups = pd.read_csv(\"/content/drive/My Drive/Duplicate Bug Report/Mozilla/M_Duplicate BRs.csv\",sep=\";\", engine='python')\n",
    "# Mozilla_nondups = pd.read_csv(\"/content/drive/My Drive/Duplicate Bug Report/Mozilla/M_NonDuplicate BRs.csv\",sep=\";\", engine='python')\n",
    "# Mozilla_combined = pd.concat([Mozilla_dups, Mozilla_nondups], ignore_index=True, sort=False)\n",
    "\n",
    "# ThunderBird_dups = pd.read_csv(\"/content/drive/My Drive/Duplicate Bug Report/ThunderBird/dup_TB.csv\",sep=\";\", engine='python')\n",
    "# ThunderBird_nondups = pd.read_csv(\"/content/drive/My Drive/Duplicate Bug Report/ThunderBird/Nondup_TB.csv\",sep=\";\", engine='python')\n",
    "# ThunderBird_combined = pd.concat([ThunderBird_dups, ThunderBird_nondups], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eE21tD7TlSSS",
    "outputId": "1f256f5f-2b9b-4119-8458-26877ba2e207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    34222\n",
       "1    12686\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking distribution of Label column\n",
    "Eclipse_combined.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dLmlhdRK5Cd-"
   },
   "outputs": [],
   "source": [
    "# Creating new column to concat Title and Description into one column called Report for the pair of bug reports. \n",
    "Eclipse_combined['Report1'] = Eclipse_combined['Title1'] +\" \"+ Eclipse_combined['Description1']\n",
    "Eclipse_combined['Report2'] = Eclipse_combined['Title2'] +\" \"+ Eclipse_combined['Description2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "5NgRbNmq5g_m",
    "outputId": "3ccaf8cb-0d46-4ce5-c5d7-5fac84e427a3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report1_n</th>\n",
       "      <th>Report2_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11048</th>\n",
       "      <td>npe prevents from applying a patch team  apply...</td>\n",
       "      <td>npe in label.setbackground choosing show in br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20231</th>\n",
       "      <td>dav site explorer should update lazily as you ...</td>\n",
       "      <td>keybindings copy action in view. binding crtlc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26892</th>\n",
       "      <td>preferences invalid preference pages are still...</td>\n",
       "      <td>rundebug hoverbehavior incorrect on workspace ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Report1_n  \\\n",
       "11048  npe prevents from applying a patch team  apply...   \n",
       "20231  dav site explorer should update lazily as you ...   \n",
       "26892  preferences invalid preference pages are still...   \n",
       "\n",
       "                                               Report2_n  \n",
       "11048  npe in label.setbackground choosing show in br...  \n",
       "20231  keybindings copy action in view. binding crtlc...  \n",
       "26892  rundebug hoverbehavior incorrect on workspace ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the records in the X_train dataframe\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model(it may takes 2-3 mins) ...\n",
      "1,000 sentences embedded.\n",
      "2,000 sentences embedded.\n",
      "3,000 sentences embedded.\n",
      "4,000 sentences embedded.\n",
      "5,000 sentences embedded.\n",
      "6,000 sentences embedded.\n",
      "7,000 sentences embedded.\n",
      "8,000 sentences embedded.\n",
      "9,000 sentences embedded.\n",
      "10,000 sentences embedded.\n",
      "11,000 sentences embedded.\n",
      "12,000 sentences embedded.\n",
      "13,000 sentences embedded.\n",
      "14,000 sentences embedded.\n",
      "15,000 sentences embedded.\n",
      "16,000 sentences embedded.\n",
      "17,000 sentences embedded.\n",
      "18,000 sentences embedded.\n",
      "19,000 sentences embedded.\n",
      "20,000 sentences embedded.\n",
      "21,000 sentences embedded.\n",
      "22,000 sentences embedded.\n",
      "23,000 sentences embedded.\n",
      "24,000 sentences embedded.\n",
      "25,000 sentences embedded.\n",
      "26,000 sentences embedded.\n",
      "27,000 sentences embedded.\n",
      "28,000 sentences embedded.\n",
      "29,000 sentences embedded.\n",
      "30,000 sentences embedded.\n",
      "31,000 sentences embedded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 17:52:25.257056: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 50)           51270300    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " man_dist (ManDist)             (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,270,300\n",
      "Trainable params: 70,200\n",
      "Non-trainable params: 51,200,100\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 8s 360ms/step - loss: 0.2624 - accuracy: 0.7375 - val_loss: 0.2502 - val_accuracy: 0.7498\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 4s 320ms/step - loss: 0.2623 - accuracy: 0.7375 - val_loss: 0.2502 - val_accuracy: 0.7498\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 4s 310ms/step - loss: 0.2621 - accuracy: 0.7378 - val_loss: 0.2501 - val_accuracy: 0.7498\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 4s 318ms/step - loss: 0.2618 - accuracy: 0.7379 - val_loss: 0.2500 - val_accuracy: 0.7502\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 4s 312ms/step - loss: 0.2616 - accuracy: 0.7382 - val_loss: 0.2499 - val_accuracy: 0.7502\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 4s 316ms/step - loss: 0.2612 - accuracy: 0.7385 - val_loss: 0.2499 - val_accuracy: 0.7502\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 4s 311ms/step - loss: 0.2608 - accuracy: 0.7387 - val_loss: 0.2498 - val_accuracy: 0.7502\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 4s 311ms/step - loss: 0.2603 - accuracy: 0.7393 - val_loss: 0.2496 - val_accuracy: 0.7502\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.2597 - accuracy: 0.7395 - val_loss: 0.2492 - val_accuracy: 0.7505\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 4s 312ms/step - loss: 0.2589 - accuracy: 0.7398 - val_loss: 0.2487 - val_accuracy: 0.7505\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.2580 - accuracy: 0.7409 - val_loss: 0.2482 - val_accuracy: 0.7508\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 5s 359ms/step - loss: 0.2567 - accuracy: 0.7417 - val_loss: 0.2476 - val_accuracy: 0.7511\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 5s 377ms/step - loss: 0.2549 - accuracy: 0.7422 - val_loss: 0.2467 - val_accuracy: 0.7508\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 5s 323ms/step - loss: 0.2525 - accuracy: 0.7442 - val_loss: 0.2451 - val_accuracy: 0.7505\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 4s 318ms/step - loss: 0.2494 - accuracy: 0.7458 - val_loss: 0.2434 - val_accuracy: 0.7492\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 5s 356ms/step - loss: 0.2460 - accuracy: 0.7483 - val_loss: 0.2419 - val_accuracy: 0.7495\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 6s 452ms/step - loss: 0.2424 - accuracy: 0.7507 - val_loss: 0.2403 - val_accuracy: 0.7489\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 7s 497ms/step - loss: 0.2384 - accuracy: 0.7536 - val_loss: 0.2390 - val_accuracy: 0.7479\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 9s 644ms/step - loss: 0.2344 - accuracy: 0.7564 - val_loss: 0.2377 - val_accuracy: 0.7486\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 9s 632ms/step - loss: 0.2303 - accuracy: 0.7594 - val_loss: 0.2364 - val_accuracy: 0.7467\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 9s 638ms/step - loss: 0.2262 - accuracy: 0.7623 - val_loss: 0.2349 - val_accuracy: 0.7473\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 8s 550ms/step - loss: 0.2223 - accuracy: 0.7659 - val_loss: 0.2338 - val_accuracy: 0.7479\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 7s 523ms/step - loss: 0.2185 - accuracy: 0.7696 - val_loss: 0.2330 - val_accuracy: 0.7473\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 7s 508ms/step - loss: 0.2149 - accuracy: 0.7734 - val_loss: 0.2321 - val_accuracy: 0.7457\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 6s 432ms/step - loss: 0.2117 - accuracy: 0.7769 - val_loss: 0.2310 - val_accuracy: 0.7460\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 6s 406ms/step - loss: 0.2086 - accuracy: 0.7801 - val_loss: 0.2299 - val_accuracy: 0.7479\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 6s 418ms/step - loss: 0.2055 - accuracy: 0.7826 - val_loss: 0.2287 - val_accuracy: 0.7470\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 6s 408ms/step - loss: 0.2029 - accuracy: 0.7846 - val_loss: 0.2278 - val_accuracy: 0.7451\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 6s 418ms/step - loss: 0.2002 - accuracy: 0.7891 - val_loss: 0.2270 - val_accuracy: 0.7451\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 6s 404ms/step - loss: 0.1978 - accuracy: 0.7918 - val_loss: 0.2260 - val_accuracy: 0.7467\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 6s 468ms/step - loss: 0.1955 - accuracy: 0.7945 - val_loss: 0.2255 - val_accuracy: 0.7444\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 7s 507ms/step - loss: 0.1932 - accuracy: 0.7968 - val_loss: 0.2246 - val_accuracy: 0.7463\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 7s 525ms/step - loss: 0.1910 - accuracy: 0.7991 - val_loss: 0.2239 - val_accuracy: 0.7451\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 9s 618ms/step - loss: 0.1888 - accuracy: 0.8016 - val_loss: 0.2231 - val_accuracy: 0.7463\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 8s 593ms/step - loss: 0.1867 - accuracy: 0.8050 - val_loss: 0.2220 - val_accuracy: 0.7467\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 8s 586ms/step - loss: 0.1845 - accuracy: 0.8073 - val_loss: 0.2214 - val_accuracy: 0.7473\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 8s 595ms/step - loss: 0.1825 - accuracy: 0.8093 - val_loss: 0.2208 - val_accuracy: 0.7470\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 7s 527ms/step - loss: 0.1806 - accuracy: 0.8119 - val_loss: 0.2202 - val_accuracy: 0.7482\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 7s 537ms/step - loss: 0.1787 - accuracy: 0.8144 - val_loss: 0.2194 - val_accuracy: 0.7473\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 7s 518ms/step - loss: 0.1767 - accuracy: 0.8159 - val_loss: 0.2189 - val_accuracy: 0.7467\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 7s 489ms/step - loss: 0.1748 - accuracy: 0.8182 - val_loss: 0.2184 - val_accuracy: 0.7463\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 7s 470ms/step - loss: 0.1730 - accuracy: 0.8202 - val_loss: 0.2178 - val_accuracy: 0.7460\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 7s 520ms/step - loss: 0.1711 - accuracy: 0.8220 - val_loss: 0.2174 - val_accuracy: 0.7473\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 7s 491ms/step - loss: 0.1693 - accuracy: 0.8240 - val_loss: 0.2167 - val_accuracy: 0.7444\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.1675 - accuracy: 0.8257 - val_loss: 0.2163 - val_accuracy: 0.7473\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 7s 472ms/step - loss: 0.1659 - accuracy: 0.8278 - val_loss: 0.2158 - val_accuracy: 0.7467\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 7s 490ms/step - loss: 0.1642 - accuracy: 0.8304 - val_loss: 0.2156 - val_accuracy: 0.7463\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 7s 484ms/step - loss: 0.1625 - accuracy: 0.8319 - val_loss: 0.2152 - val_accuracy: 0.7460\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 8s 575ms/step - loss: 0.1609 - accuracy: 0.8335 - val_loss: 0.2150 - val_accuracy: 0.7463\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 0.1594 - accuracy: 0.8355 - val_loss: 0.2146 - val_accuracy: 0.7470\n",
      "Training time finished.\n",
      "50 epochs in       321.47\n"
     ]
    }
   ],
   "source": [
    "# Split to train test\n",
    "Train, Test = train_test_split(Eclipse_combined, test_size=0.33, random_state=42)\n",
    "\n",
    "# Load training set and resetting index\n",
    "train_df = Train.reset_index()\n",
    "for q in ['Report1', 'Report2']:\n",
    "    train_df[q + '_n'] = train_df[q]\n",
    "\n",
    "# Make word2vec embeddings\n",
    "embedding_dim = 300\n",
    "max_seq_length = 20\n",
    "use_w2v = True\n",
    "\n",
    "#trigerring make_w2v_embeddings support function from 'util.py' for the word embedding and vectorization process\n",
    "#detailed in the final Paper submission\n",
    "train_df, embeddings = make_w2v_embeddings(train_df, embedding_dim=embedding_dim, empty_w2v=use_w2v)\n",
    "\n",
    "# Split to train validation, assigning size\n",
    "validation_size = int(len(train_df) * 0.1)\n",
    "training_size = len(train_df) - validation_size\n",
    "\n",
    "#Selecting X and y\n",
    "X = train_df[['Report1_n','Report2_n']]\n",
    "Y = train_df['Label']\n",
    "\n",
    "#Train and validation split\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\n",
    "\n",
    "#trigerring split_and_zero_padding support function from 'util.py' for both train and validation dataframes\n",
    "X_train = split_and_zero_padding(X_train, max_seq_length)\n",
    "X_validation = split_and_zero_padding(X_validation, max_seq_length)\n",
    "\n",
    "# Convert labels to their numpy representations\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values\n",
    "\n",
    "# Make sure shape of dataframe is as expected\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)\n",
    "\n",
    "# -- BEGIN MODEL ----\n",
    "\n",
    "# Model variables\n",
    "gpus = 2\n",
    "batch_size = 1024 * gpus\n",
    "n_epoch = 50\n",
    "n_hidden = 50\n",
    "\n",
    "# Define the shared sequential model\n",
    "x = Sequential()\n",
    "#using word2vec generated embeddings\n",
    "x.add(Embedding(len(embeddings), embedding_dim,\n",
    "                weights=[embeddings], input_shape=(max_seq_length,), \n",
    "                trainable=False))\n",
    "#Adding the LSTM layer for the Siamese Signal Subnet Compression\n",
    "x.add(LSTM(n_hidden))\n",
    "shared_model = x\n",
    "\n",
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "# Rolled up into a Manhattan Distance model\n",
    "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\n",
    "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])\n",
    "\n",
    "# Build model with MSE loss, Adam optimizer and optimizing for accuracy \n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Display Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Start training over the epochs\n",
    "training_start_time = time()\n",
    "malstm_trained = model.fit([X_train['left'], X_train['right']], Y_train,\n",
    "                           batch_size=batch_size, epochs=n_epoch,\n",
    "                           validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
    "training_end_time = time()\n",
    "\n",
    "print(\"Training time finished.\\n%d epochs in %12.2f\" % (n_epoch,training_end_time - training_start_time))\n",
    "\n",
    "\n",
    "#Saving the model to a file for inference \n",
    "model.save('./data/BugClassifierLSTM.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351(max: 0.7373)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(malstm_trained.history['accuracy'])\n",
    "plt.plot(malstm_trained.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(212)\n",
    "plt.plot(malstm_trained.history['loss'])\n",
    "plt.plot(malstm_trained.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout(h_pad=1.0)\n",
    "plt.savefig('./data/history-graph.png')\n",
    "\n",
    "print(str(malstm_trained.history['val_accuracy'][-1])[:6] +\n",
    "      \"(max: \" + str(max(malstm_trained.history['val_accuracy']))[:6] + \")\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report1_n</th>\n",
       "      <th>Report2_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>[311, 1067, 8974, 15, 616, 81, 8974, 7, 199, 1...</td>\n",
       "      <td>[1067, 576, 999, 8975, 8975, 1979, 8976, 1598,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39333</th>\n",
       "      <td>[859, 40, 115, 7697, 1501, 45211, 8198, 613, 2...</td>\n",
       "      <td>[63, 65421, 3052, 1621, 980, 4746, 2389, 4538,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13524</th>\n",
       "      <td>[2, 920, 1615, 914, 180, 341, 1451, 87057, 912...</td>\n",
       "      <td>[87058, 1120, 278, 87059, 2407, 100, 3565, 376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32453</th>\n",
       "      <td>[7472, 28229, 165315, 563, 319, 2123, 2796, 64...</td>\n",
       "      <td>[8935, 3456, 4114, 1026, 189, 4344, 3968, 340,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37068</th>\n",
       "      <td>[7472, 4999, 4994, 89, 1454, 76, 964, 81, 89, ...</td>\n",
       "      <td>[405, 313, 7322, 68, 751, 1548, 10718, 986, 11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Report1_n  \\\n",
       "465    [311, 1067, 8974, 15, 616, 81, 8974, 7, 199, 1...   \n",
       "39333  [859, 40, 115, 7697, 1501, 45211, 8198, 613, 2...   \n",
       "13524  [2, 920, 1615, 914, 180, 341, 1451, 87057, 912...   \n",
       "32453  [7472, 28229, 165315, 563, 319, 2123, 2796, 64...   \n",
       "37068  [7472, 4999, 4994, 89, 1454, 76, 964, 81, 89, ...   \n",
       "\n",
       "                                               Report2_n  \n",
       "465    [1067, 576, 999, 8975, 8975, 1979, 8976, 1598,...  \n",
       "39333  [63, 65421, 3052, 1621, 980, 4746, 2389, 4538,...  \n",
       "13524  [87058, 1120, 278, 87059, 2407, 100, 3565, 376...  \n",
       "32453  [8935, 3456, 4114, 1026, 189, 4344, 3968, 340,...  \n",
       "37068  [405, 313, 7322, 68, 751, 1548, 10718, 986, 11...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the first few data points of the Test dataset\n",
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 50)           66271200    ['input_17[0][0]',               \n",
      "                                                                  'input_18[0][0]']               \n",
      "                                                                                                  \n",
      " man_dist_8 (ManDist)           (None, 1)            0           ['sequential_8[0][0]',           \n",
      "                                                                  'sequential_8[1][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,271,200\n",
      "Trainable params: 70,200\n",
      "Non-trainable params: 66,201,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Loading libraries for test run\n",
    "import pandas as pd\n",
    "from util import make_w2v_embeddings\n",
    "from util import split_and_zero_padding\n",
    "from util import ManDist\n",
    "\n",
    "# Load testing set\n",
    "test_df = X_test\n",
    "\n",
    "# Make sure shape is ok\n",
    "assert X_test['left'].shape == X_test['right'].shape\n",
    "\n",
    "# --  INFERENCE FROM MODEL ---\n",
    "\n",
    "#Loading previously saved model\n",
    "model = keras.models.load_model('./data/BugClassifierLSTM.h5', custom_objects={'ManDist': ManDist})\n",
    "model.summary()\n",
    "\n",
    "#making predictions on test set\n",
    "y_test_pred = model.predict([X_test['left'], X_test['right']])\n",
    "\n",
    "#Setting threshold for Manhattan distance cut-off\n",
    "threshold = 0.5\n",
    "\n",
    "#Predicting Label for each value in the test set\n",
    "Y_pred_final = np.where(y_test_pred > threshold, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC_score of model :  0.5335104576737897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84     11238\n",
      "           1       0.55      0.10      0.16      4242\n",
      "\n",
      "    accuracy                           0.73     15480\n",
      "   macro avg       0.65      0.53      0.50     15480\n",
      "weighted avg       0.69      0.73      0.65     15480\n",
      "\n",
      "[[10905   333]\n",
      " [ 3832   410]]\n"
     ]
    }
   ],
   "source": [
    "#Printing the performance of results obtained from model on the test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(\"ROC_AUC_score of model : \",roc_auc_score(y_test, Y_pred_final))\n",
    "print(classification_report(y_test, Y_pred_final))\n",
    "print(confusion_matrix(y_test, Y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BugReportDuplicationAnalysis_DSCI644_v1.0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
